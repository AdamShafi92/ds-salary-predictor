{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "from time import time, sleep\n",
    "from datetime import datetime\n",
    "from random import randrange\n",
    "\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import glob\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk import PorterStemmer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General functions to load the data and carry out some basic Pandas cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path=r'scraped_data/base'):\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    df_list = [pd.read_csv(file, index_col=None, header=0) for file in all_files]\n",
    "    return pd.concat(df_list, axis=0, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df=df.copy()\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.dropna(subset=['Salary'],inplace=True)\n",
    "    df['Location']= df['Location1'].fillna(df['Location2'])\n",
    "    df.drop(['Location1','Location2'],axis=1,inplace=True)\n",
    "    df = df.apply(lambda x: x.str.replace('\\nnew','').str.replace('\\n',''))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job title must be lemmatized and cleaned so it can be vectorized later on. Stemming was not used as this can limit interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentence(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in tokens:\n",
    "        if tag.startswith('NN'):\n",
    "            pos = 'n'\n",
    "        elif tag.startswith('VB'):\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            pos = 'a'\n",
    "        lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_title(array):\n",
    "    stopwords = English.Defaults.stop_words\n",
    "    array = (array\n",
    "                .str.lower()\n",
    "                .str.replace('[0-9£–]','',regex=True)\n",
    "                .apply(word_tokenize)\n",
    "                .apply(lambda x: [i for i in x if i not in stopwords])\n",
    "                .apply(lambda x: [i for i in x if len(i) >1])\n",
    "                .apply(pos_tag)\n",
    "                .apply(lemmatize_sentence)\n",
    "                .apply(' '.join)\n",
    "                .apply(lambda x: x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
    "            )\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_df(x,y):\n",
    "    x = literal_eval(x)\n",
    "    y = literal_eval(y)\n",
    "    k = dict(zip(x,y))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_data(df):\n",
    "    company_info = df.copy()\n",
    "    company_info.columns = ['Company','heading','value']\n",
    "    company_info2 = pd.DataFrame(list(company_info.apply(lambda x: list_df(x.heading,x.value),axis=1)))\n",
    "    company_info = pd.merge(company_info,company_info2, left_index=True, right_index=True)\n",
    "    company_info.drop(['heading','value','Website','Headquarters'],axis=1,inplace=True)    \n",
    "    company_info.fillna('no_data',inplace=True)\n",
    "    company_info = company_info.sort_values(by='Employees')\n",
    "    company_info['Company'] = company_info['Company'].str.replace('+',' ')\n",
    "    company_info.drop_duplicates(subset='Company',inplace=True)\n",
    "    return company_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salary(df,col):\n",
    "    df=df.copy()\n",
    "    # pull salary information if in title\n",
    "    reg1 = '(?<=£)([0-9,-k]+)'\n",
    "    df['TitleSalary'] = df['Title'].apply(lambda x: ' '.join(re.findall(reg1,x)))\n",
    "    df['TitleSalary'] = df['TitleSalary'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    df[col] = df[col].fillna(df['TitleSalary'])\n",
    "    df.drop('TitleSalary',axis=1,inplace=True)   \n",
    "    \n",
    "    reg2 = r'(?<=£)([0-9,]+)'\n",
    "    df['min_salary'] = df[col].apply(lambda x: re.findall(reg2,x)[0].replace(',','')).astype(float)\n",
    "    df['max_salary'] = df[col].apply(lambda x: re.findall(reg2,x)[-1].replace(',','')).astype(float)\n",
    "    \n",
    "    reg3 = r'([A-z]+)'\n",
    "    df['salary_period'] = df[col].apply(lambda x: re.findall(reg3,x)[1])\n",
    "    df.drop([col],axis=1,inplace=True)\n",
    "    \n",
    "    # Turning hourly/daily salaries into yearly. In the end only yearly salaries were used\n",
    "    \n",
    "    salary_period_calc = {\n",
    "                            'hour':2000, # 40 hour weeks, 50 weeks\n",
    "                            'year': 1,   \n",
    "                            'day': 240,  # 240 working days per year\n",
    "                            'month': 12, \n",
    "                            'week': 50   # 50 working weeks\n",
    "                            }  \n",
    "    \n",
    "    df['min_salary'] = df['min_salary'] * df['salary_period'].map(salary_period_calc)\n",
    "    df['max_salary'] = df['max_salary'] * df['salary_period'].map(salary_period_calc)\n",
    "    df['mid_salary'] = (df['min_salary']+df['max_salary'])/2    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_location(array):\n",
    "    array[array.str.contains('London')] = 'London' # This causes setting with copy warning\n",
    "    array = (array\n",
    "             .str.replace('[A-Z]{1,2}\\d[A-Z\\d]? ?\\d[A-Z]{2}','',regex=True) # remove postcodes\n",
    "             .str.replace(r'[A-Z]{1,2}\\d[A-Z\\d]?','',regex=True) # remove postcoddes\n",
    "             .apply(lambda x: x.strip())\n",
    "             .str.replace(r'[^\\w\\s]','',regex=True)\n",
    "             .str.replace(' ','_')         \n",
    "            )\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(df):\n",
    "    df = df.copy()\n",
    "    df.columns = ['url','description']\n",
    "    df['len'] = df['description'].apply(len)\n",
    "    df = df.sort_values(by='len',ascending=False)\n",
    "    df.drop_duplicates(subset = 'url',inplace=True)\n",
    "    df.drop('len',axis=1,inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempting to get years experience from the job description. This didn't provide much data and wasn't used.\n",
    "\n",
    "def get_years(array):\n",
    "    X = array\n",
    "    reg = r'\\d*\\s(?=years e)'\n",
    "    X = X.apply(lambda x: x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
    "    return X.apply(lambda x: re.findall(reg,x)).apply(lambda x: clean_years(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_years(years):\n",
    "    if len(years)>0:\n",
    "        return years[0].strip()\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is similar to the job title function but with some subtle differences due to formatting.\n",
    "\n",
    "def clean_text(array):\n",
    "    stopwords = English.Defaults.stop_words   \n",
    "    array=(array\n",
    "            .apply(lambda x: ' '.join(x.split('\\\\n')))\n",
    "            .str.lower()\n",
    "            .str.replace('[0-9£–]','',regex=True)\n",
    "            .apply(word_tokenize)\n",
    "            .apply(lambda x: [i for i in x if i not in stopwords])\n",
    "            .apply(pos_tag)\n",
    "            .apply(lemmatize_sentence)\n",
    "            .apply(' '.join)\n",
    "            .apply(lambda x: x.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation))))\n",
    "            .str.strip()) \n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translator(text, conversion_dict, before=None):\n",
    "    \"\"\"\n",
    "    Translate words from a text using a conversion dictionary\n",
    "\n",
    "    Arguments:\n",
    "        text: the text to be translated\n",
    "        conversion_dict: the conversion dictionary\n",
    "        before: a function to transform the input\n",
    "        (by default it will to a lowercase)\n",
    "    \"\"\"\n",
    "    # if empty:\n",
    "    if not text: return text\n",
    "    # preliminary transformation:\n",
    "    before = before or str.lower\n",
    "    t = before(text)\n",
    "    for key, value in conversion_dict.items():\n",
    "        t = t.replace(key, value)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for EDA\n",
    "\n",
    "def job_cat(x):\n",
    "    if 'analys' in x:\n",
    "        return 'Analyst'\n",
    "    elif 'scien' in x:\n",
    "        return 'Scientist'\n",
    "    elif 'enginee' in x:\n",
    "        return 'Engineer'\n",
    "    else:\n",
    "        return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_merged(df):\n",
    "    \n",
    "    replacements = {\n",
    "    'team work:':'teamwork',\n",
    "    'power bi':'powerbi',\n",
    "    \"' s'\":' ',\n",
    "    \" s \":' ',\n",
    "    \"''\":' ',\n",
    "    '’':' ',\n",
    "    'big query':'bigquery'} # manual replacements\n",
    "    \n",
    "    df=df.copy()\n",
    "    df['description'] = df['description'].str.strip().replace('',np.nan).fillna(df['Summary'])\n",
    "    df.drop(['url','Summary','min_salary','max_salary','Company'],axis=1,inplace=True)\n",
    "    df.fillna('no_data',inplace=True)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    df['description'] = df['description'].apply(lambda x: translator(x,replacements))\n",
    "    df['title_category'] = df['Title'].apply(lambda x: job_cat(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers removed -  low salaries which may be internships or incorrect data \n",
    "# There are very few salaries over 200k and this is the region where there is much more variance.\n",
    "\n",
    "def remove_outliers(df,col):\n",
    "    return df[(df[col]>16000) & (df[col]<200000)]  # Outliers removed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Cleanup Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scraped jobs data\n",
    "\n",
    "df = load_data()\n",
    "df = clean_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scraped company data\n",
    "\n",
    "company_info = load_data(path=r'scraped_data/companies')\n",
    "company_info = clean_company_data(company_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & clean full descriptions\n",
    "\n",
    "full_desc = load_data(path=r'scraped_data/descriptions')\n",
    "full_desc = remove_dupes(full_desc)\n",
    "full_desc['years_exp'] = get_years(full_desc['description'])\n",
    "full_desc['description'] = clean_text(full_desc['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-062a9a7b5460>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  array[array.str.contains('London')] = 'London'\n"
     ]
    }
   ],
   "source": [
    "# Clean jobs data\n",
    "\n",
    "df['Title'] = clean_title(df['Title'])\n",
    "df = clean_salary(df,'Salary')\n",
    "df['Location'] = clean_location(df['Location'])\n",
    "df = remove_outliers(df,'mid_salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>salary_period</th>\n",
       "      <th>mid_salary</th>\n",
       "      <th>Employees</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>description</th>\n",
       "      <th>years_exp</th>\n",
       "      <th>title_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high statistical data scientist g</td>\n",
       "      <td>London</td>\n",
       "      <td>year</td>\n",
       "      <td>28996.0</td>\n",
       "      <td>no_data</td>\n",
       "      <td>no_data</td>\n",
       "      <td>no_data</td>\n",
       "      <td>role require apply knowledge statistic program...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>senior statistical data scientist g</td>\n",
       "      <td>London</td>\n",
       "      <td>year</td>\n",
       "      <td>34090.0</td>\n",
       "      <td>no_data</td>\n",
       "      <td>no_data</td>\n",
       "      <td>no_data</td>\n",
       "      <td>role require apply knowledge statistic program...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>year</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>51 to 200</td>\n",
       "      <td>Consulting and Business Services</td>\n",
       "      <td>less than £1m</td>\n",
       "      <td>data scientist london   united kingdom salary ...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>year</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>51 to 200</td>\n",
       "      <td>Consulting and Business Services</td>\n",
       "      <td>less than £1m</td>\n",
       "      <td>data scientist london   united kingdom salary ...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data scientist</td>\n",
       "      <td>London</td>\n",
       "      <td>day</td>\n",
       "      <td>132000.0</td>\n",
       "      <td>51 to 200</td>\n",
       "      <td>Consulting and Business Services</td>\n",
       "      <td>less than £1m</td>\n",
       "      <td>data scientist day remote london base month ch...</td>\n",
       "      <td>no_data</td>\n",
       "      <td>Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title Location salary_period  mid_salary  \\\n",
       "0    high statistical data scientist g   London          year     28996.0   \n",
       "2  senior statistical data scientist g   London          year     34090.0   \n",
       "4                       data scientist   London          year     65000.0   \n",
       "6                       data scientist   London          year     67500.0   \n",
       "8                       data scientist   London           day    132000.0   \n",
       "\n",
       "   Employees                          Industry        Revenue  \\\n",
       "0    no_data                           no_data        no_data   \n",
       "2    no_data                           no_data        no_data   \n",
       "4  51 to 200  Consulting and Business Services  less than £1m   \n",
       "6  51 to 200  Consulting and Business Services  less than £1m   \n",
       "8  51 to 200  Consulting and Business Services  less than £1m   \n",
       "\n",
       "                                         description years_exp title_category  \n",
       "0  role require apply knowledge statistic program...   no_data      Scientist  \n",
       "2  role require apply knowledge statistic program...   no_data      Scientist  \n",
       "4  data scientist london   united kingdom salary ...   no_data      Scientist  \n",
       "6  data scientist london   united kingdom salary ...   no_data      Scientist  \n",
       "8  data scientist day remote london base month ch...   no_data      Scientist  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge scraped data\n",
    "\n",
    "df = pd.merge(df,company_info,left_on='Company',right_on='Company',how='left')\n",
    "df = pd.merge(df,full_desc,left_on='url',right_on='url')\n",
    "df = clean_merged(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('jobs_desc.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Imb",
   "language": "python",
   "name": "imb_py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
